{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600799055479",
   "display_name": "Python 3.7.7 64-bit ('mlenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     assets  liabilities    income  credit_score  mortgage   status\n0  0.210859     0.452865  0.281367      0.628039  0.302682     deny\n1  0.395018     0.661153  0.330622      0.638439  0.502831  approve\n2  0.291186     0.593432  0.438436      0.434863  0.315574  approve\n3  0.458640     0.576156  0.744167      0.291324  0.394891  approve\n4  0.463470     0.292414  0.489887      0.811384  0.566605  approve",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>assets</th>\n      <th>liabilities</th>\n      <th>income</th>\n      <th>credit_score</th>\n      <th>mortgage</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.210859</td>\n      <td>0.452865</td>\n      <td>0.281367</td>\n      <td>0.628039</td>\n      <td>0.302682</td>\n      <td>deny</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.395018</td>\n      <td>0.661153</td>\n      <td>0.330622</td>\n      <td>0.638439</td>\n      <td>0.502831</td>\n      <td>approve</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.291186</td>\n      <td>0.593432</td>\n      <td>0.438436</td>\n      <td>0.434863</td>\n      <td>0.315574</td>\n      <td>approve</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.458640</td>\n      <td>0.576156</td>\n      <td>0.744167</td>\n      <td>0.291324</td>\n      <td>0.394891</td>\n      <td>approve</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.463470</td>\n      <td>0.292414</td>\n      <td>0.489887</td>\n      <td>0.811384</td>\n      <td>0.566605</td>\n      <td>approve</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#read in data\n",
    "data = Path('../Resources/loans.csv')\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate features from target\n",
    "y = df[\"status\"]\n",
    "X = df.drop(columns=\"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(75, 5)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Use the train_test_split function to create training and testing subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegression(max_iter=200, random_state=1)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#train model using training data\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Prediction   Actual\n0        deny     deny\n1        deny  approve\n2        deny     deny\n3     approve     deny\n4        deny     deny\n5        deny  approve\n6        deny     deny\n7     approve     deny\n8        deny     deny\n9     approve  approve\n10       deny  approve\n11       deny     deny\n12       deny     deny\n13       deny  approve\n14       deny     deny\n15    approve  approve\n16       deny  approve\n17    approve  approve\n18       deny  approve\n19       deny  approve",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Prediction</th>\n      <th>Actual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>deny</td>\n      <td>deny</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>deny</td>\n      <td>approve</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>deny</td>\n      <td>deny</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>approve</td>\n      <td>deny</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>deny</td>\n      <td>deny</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>deny</td>\n      <td>approve</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>deny</td>\n      <td>deny</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>approve</td>\n      <td>deny</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>deny</td>\n      <td>deny</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>approve</td>\n      <td>approve</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>deny</td>\n      <td>approve</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>deny</td>\n      <td>deny</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>deny</td>\n      <td>deny</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>deny</td>\n      <td>approve</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>deny</td>\n      <td>deny</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>approve</td>\n      <td>approve</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>deny</td>\n      <td>approve</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>approve</td>\n      <td>approve</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>deny</td>\n      <td>approve</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>deny</td>\n      <td>approve</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#make predictions \n",
    "y_pred = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.52\n"
    }
   ],
   "source": [
    "#check accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 3,  9],\n       [ 3, 10]])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n     approve       0.50      0.25      0.33        12\n        deny       0.53      0.77      0.62        13\n\n    accuracy                           0.52        25\n   macro avg       0.51      0.51      0.48        25\nweighted avg       0.51      0.52      0.48        25\n\n"
    }
   ],
   "source": [
    "#generate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}